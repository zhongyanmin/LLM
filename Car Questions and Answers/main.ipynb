{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pdfplumber\n",
    "import torch\n",
    "import transformers\n",
    "import jieba\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from rank_bm25 import BM25Okapi\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': '“前排座椅通风”的相关内容在第几页？', 'answer': '', 'reference': ''}\n",
      "pages: 354\n"
     ]
    }
   ],
   "source": [
    "questions = json.load(open(\"questions.json\", encoding=\"utf-8\"))\n",
    "print(questions[0])\n",
    "\n",
    "pdf = pdfplumber.open(\"初赛训练数据集.pdf\")\n",
    "print(\"pages:\", len(pdf.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_content = []\n",
    "for page_idx in range(len(pdf.pages)):\n",
    "    pdf_content.append({\n",
    "        'page': 'page_' + str(page_idx + 1),\n",
    "        'content': pdf.pages[page_idx].extract_text()\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page': 'page_1',\n",
       " 'content': '欢迎\\n感谢您选择了具有优良安全性、舒适性、动力性和经济性的Lynk&Co领克汽车。\\n首次使用前请仔细、完整地阅读本手册内容，将有助于您更好地了解和使用车辆。\\n本手册中的所有资料均为出版时的最新资料，但本公司将对产品进行不断的改进和优化，您所购的车辆可能与本手册中的描述有所不同，请以实际\\n接收的车辆为准。\\n如您有任何问题，或需要预约服务，请拨打电话4006-010101联系我们。您也可以开车前往Lynk&Co领克中心。\\n在抵达之前，请您注意驾车安全。\\n©领克汽车销售有限公司'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_content[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFDIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ZHONGY~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.582 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "question_words = [' '.join(jieba.lcut(x['question'])) for x in questions]\n",
    "pdf_content_words = [' '.join(jieba.lcut(x['content'])) for x in pdf_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(question_words + pdf_content_words)\n",
    "\n",
    "question_feat = tfidf.transform(question_words)\n",
    "pdf_content_feat = tfidf.transform(pdf_content_words)\n",
    "\n",
    "question_feat = normalize(question_feat)\n",
    "pdf_content_feat = normalize(pdf_content_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, feat in enumerate(question_feat):\n",
    "    score = feat @ pdf_content_feat.T\n",
    "    score = score.toarray()[0]\n",
    "    max_score_page_idx = score.argsort()[-1] + 1\n",
    "\n",
    "    questions[idx]['reference'] = 'page_' + str(max_score_page_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('submit.json', 'w', encoding='utf8') as up:\n",
    "#     json.dump(questions, up, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\ZHONGY~1\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.578 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "pdf_content_words = [jieba.lcut(x['content']) for x in pdf_content]\n",
    "bm25 = BM25Okapi(pdf_content_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx in range(len(questions)):\n",
    "    doc_scores = bm25.get_scores(jieba.lcut(questions[idx][\"question\"]))\n",
    "    max_score_page_idx = doc_scores.argsort()[-1] + 1\n",
    "    questions[idx]['reference'] = 'page_' + str(max_score_page_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('submit.json', 'w', encoding='utf8') as up:\n",
    "#     json.dump(questions, up, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 + BGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('BAAI/bge-small-zh-v1.5')\n",
    "question_sentences = [x['question'] for x in questions]\n",
    "pdf_content_sentences = [x['content'] for x in pdf_content]\n",
    "\n",
    "question_embeddings = model.encode(question_sentences, normalize_embeddings=True)\n",
    "pdf_embeddings = model.encode(pdf_content_sentences, normalize_embeddings=True)\n",
    "\n",
    "for query_idx, feat in enumerate(question_embeddings):\n",
    "    score = feat @ pdf_embeddings.T\n",
    "    max_score_page_idx = score.argsort()[-1]\n",
    "    questions[query_idx]['reference'] = pdf_content[max_score_page_idx]['page']\n",
    "\n",
    "with open('submit.json', 'w', encoding='utf8') as up:\n",
    "    json.dump(questions, up, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "for query_idx, feat in enumerate(question_embeddings):\n",
    "    score1 = feat @ pdf_embeddings.T\n",
    "    score2 = bm25.get_scores(jieba.lcut(questions[query_idx][\"question\"]))\n",
    "\n",
    "    score = rankdata(score1) + rankdata(score2)\n",
    "    max_score_page_idx = score.argsort()[-1] + 1\n",
    "    questions[query_idx]['reference'] = 'page_' + str(max_score_page_idx)\n",
    "\n",
    "with open('submit.json', 'w', encoding='utf8') as up:\n",
    "    json.dump(questions, up, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gemini(apikey, text):\n",
    "    url = f'https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key={apikey}'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        'contents': [\n",
    "            {\n",
    "                'parts': [\n",
    "                    {\"text\": text}\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        response_data = response.json()\n",
    "        return response_data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-base')\n",
    "rerank_model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-base')\n",
    "rerank_model.cuda()\n",
    "rerank_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [23:16:33<00:00, 83793.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "此问题无法从提供的资料中回答。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "apikey = 'AIzaSyC7tR3iQJXs6_ittg0r8XwYNhobklLh7JE'\n",
    "\n",
    "# prompt = \"我今天心情不好，给我讲个笑话吧！\"\n",
    "# answer = ask_gemini(apikey, prompt)['candidates'][0]['content']['parts'][0]['text']\n",
    "# print(answer)\n",
    "\n",
    "# for query_idx in tqdm(range(len(questions))):\n",
    "for query_idx in tqdm(range(1)):\n",
    "    doc_scores = bm25.get_scores(jieba.lcut(questions[query_idx][\"question\"]))\n",
    "    max_score_page_idxs = doc_scores.argsort()[-4:]\n",
    "\n",
    "    pairs = []\n",
    "    for idx in max_score_page_idxs:\n",
    "        pairs.append([questions[query_idx][\"question\"], pdf_content[idx]['content']])\n",
    "\n",
    "    inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt', max_length=512)\n",
    "    with torch.no_grad():\n",
    "        inputs = {key: inputs[key].cuda() for key in inputs.keys()}\n",
    "        scores = rerank_model(**inputs, return_dict=True).logits.view(-1, ).float()\n",
    "    max_score_page_idx = max_score_page_idxs[scores.cpu().numpy().argmax()]\n",
    "    questions[query_idx]['reference'] = 'page_' + str(max_score_page_idx + 1)\n",
    "\n",
    "    # prompt = '''你是一个汽车专家，帮我结合给定的资料，回答下面的问题。如果问题无法从资料中获得，或无法从资料中进行回答，请无法回答问题。如果问题可以从资料中获得，则请逐步回答。\n",
    "    # 资料：{0}\n",
    "\n",
    "    # 问题：{1}\n",
    "    # '''.format(\n",
    "    #     pdf_content[max_score_page_idx]['content'],\n",
    "    #     questions[query_idx][\"question\"]\n",
    "    # )\n",
    "    # print(str(prompt))\n",
    "    prompt = \"\"\"你是一个汽车专家，帮我结合给定的资料，回答下面的问题。如果问题无法从资料中获得，或无法从资料中进行回答，请无法回答问题。如果问题可以从资料中获得，则请逐步回答。\n",
    "    资料：安全出行\n",
    "        设置前排座椅加热时间\n",
    "        在中央显示屏中唤起空调控制界面，然后点击 -舒适。\n",
    "        01设置副驾驶员侧座椅加热强度及开关控制。\n",
    "        驾驶员/副驾驶员侧座椅加热分三级调节，点击控制开关后在“关-低-\n",
    "        中-高”之间循环。\n",
    "        01设置驾驶员侧座椅加热时间（5分钟、15分钟、30分钟和持\n",
    "        续）。\n",
    "        警告！\n",
    "        02设置副驾驶员侧座椅加热时间（5分钟、15分钟、30分钟和持\n",
    "        ■ 如果您或者车上的乘客（例如：病人、残疾人、无身体知觉的人 续）。\n",
    "        等）身体无法感知座椅温度，请勿使用前排座椅加热功能。\n",
    "        前排座椅通风\n",
    "        使用Lynk&CoApp打开/关闭前排座椅加热 通过空调辅助功能菜单调节\n",
    "        打开/关闭前排座椅加热图标：登录Lynk&CoApp，按下 您可以通过中央显示屏空调功能菜单，设置驾驶员/副驾驶员侧座椅\n",
    "        该图标可以打开/关闭前排座椅加热。 通风强度或关闭座椅通风功能。\n",
    "        115\n",
    "\n",
    "    问题：“前排座椅通风”的相关内容在第几页？\n",
    "    \"\"\"\n",
    "    answer = ask_gemini(apikey, prompt)['candidates'][0]['content']['parts'][0]['text']\n",
    "    print(answer)\n",
    "\n",
    "    if '无法回答' in answer:\n",
    "        answer = '结合给定的资料，无法回答问题。'\n",
    "    \n",
    "    questions[query_idx]['answer'] = answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
