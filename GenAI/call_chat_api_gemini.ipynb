{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Gemini API sucessfully!!\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import google.generativeai as genai\n",
    "from typing import List, Tuple\n",
    "import gradio as gr\n",
    "import json\n",
    "\n",
    "# Set up Gemini API key\n",
    "## TODO: Fill in your Gemini API in the \"\"\n",
    "GOOGLE_API_KEY=\"xxx\"\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "\n",
    "# Check if you have set your Gemini API successfully\n",
    "# You should see \"Set Gemini API sucessfully!!\" if nothing goes wrong.\n",
    "try:\n",
    "    model.generate_content(\n",
    "      \"test\",\n",
    "    )\n",
    "    print(\"Set Gemini API sucessfully!!\")\n",
    "except:\n",
    "    print(\"There seems to be something wrong with your Gemini API. Please follow our demonstration in the slide to get a correct one.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python\\Python311\\Lib\\site-packages\\gradio\\components\\chatbot.py:273: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Input the prompt\n",
    "prompt_for_summarization = \"Please summarize this article for me.\"\n",
    "\n",
    "# function to clear the conversation\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# function to call the model to generate\n",
    "def interact_summarization(prompt: str, article: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "      * Arguments\n",
    "\n",
    "        - prompt: the prompt that we use in this section\n",
    "\n",
    "        - article: the article to be summarized\n",
    "\n",
    "        - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
    "                The higher the temperature is, the more creative response you will get.\n",
    "    '''\n",
    "    input = f\"{prompt}\\n{article}\"\n",
    "    response = model.generate_content(\n",
    "      input,\n",
    "      generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "      safety_settings=[\n",
    "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          ]\n",
    "    )\n",
    "\n",
    "    return [(input, response.text)]\n",
    "\n",
    "# function to export the whole conversation log\n",
    "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
    "    '''\n",
    "    * Arguments\n",
    "\n",
    "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
    "\n",
    "      - article: the article to be summarized\n",
    "\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"article\": article}\n",
    "    with open(\"part1.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "\n",
    "# This part constructs the Gradio UI interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Part1: Summarization\\nFill in any article you like and let the chatbot summarize it for you!!\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_summarization, visible=False)\n",
    "    article_textbox = gr.Textbox(label=\"Article\", interactive = True, value = \"With house prices soaring, it's not easy finding somewhere to live. And this community has thrown in the towel. Meet Seattle's rolling neighborhood of RVs, where each unassuming vehicle is a capsule home. The unusual format has been captured in a series of photographs by visual journalist Anna Erickson. Meet Bud Dodson, 57, and welcome to his home: An RV in Seattle's SoDo where he watches over the parking lot in exchange for a spot . No place like home: John Warden, 52, has turned his $200 vehicle into his home after his apartment burned down years ago . There are around 30 drivers that float in and out of this parking lot in the SoDo (South of Downtown) area of the city in Washington State. One might not notice them in the mornings as hundreds of workers in the nearby factories, such as Starbucks, park up and rush into work. But on the weekends, as the rabble flocks back to their beds, this unique group remains. John Worden, 52, has been living in his vehicle for years since his apartment burned down and he was left homeless. He told Anna his car cost $200, and doesn't drive very well. But for a home, it's just about enough. Though plan on the outside, it is a Pandora's Box inside, Anna tells DailyMail.com. 'It was scattered with trinkets that he had been collecting over the years,' she explained, 'and a pile of beer cans that he was saving to turn in for money.' For work, he panhandles while helping people find parking spaces at Safeco Field stadium, where he used to be a cook. People come and go for work in the factories nearby, but on the weekend it is just the RV-dwellers that area left . Daily life: Here Bud can be seen preparing himself a barbecue on the gravel outside his capsule home, one of about 30 in the community . Eclectic: While Bud's RV is organized and functional, John's is full of trinkets and belongings dating back years . Alongside him - most of the time - is Bud Dodson, 57. While some are forced to move about regularly, Dodson, a maintenance man, looks after the parking lot in exchange for a semi-permanent spot. His home has its own unique stamp on it. 'He had really made the RV his home and taken good care of it,' Anna described. 'It was more functional [than John's] and a cleaner space with a bed, kitchen and bathroom.' Whether organized or eclectic, however, each one is home. 'None of them seem to want to move on,' Anna said. 'It's not perfect but they seem pretty content. Move in, move out: Some have agreements to stay, but others have to keep driving around to find a spot . John works as a panhandler at Safeco Fields stadium, where he used to work as a cook . He is content with his life in between the usual confines of society . Personal: To many this may just seem like a parking lot but for these men it is a very personal space . 'Bud is very grateful, he said the parking lot owner is just such a nice guy to let him live like this.' She came across them when she stopped to ask a seemingly homeless man for directions. 'We got talking,' she said, 'and he mentioned that he lived nearby in an RV. I went round to look and there was a whole bunch of them.' Curious, she spent about two months returning to the spot, meeting with the community and building their trust. 'These RVs are their homes so it's a very personal thing,' she explained.\")\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
    "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"Send\")\n",
    "        reset_button = gr.Button(value=\"Reset\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
    "        export_button = gr.Button(value=\"Export\")\n",
    "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
    "\n",
    "\n",
    "demo.launch(debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role-Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python\\Python311\\Lib\\site-packages\\gradio\\components\\chatbot.py:273: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first one is the character you want your chatbot to play\n",
    "# The second one is the prompt to make the chatbot be a certain character\n",
    "character_for_chatbot = \"pirate\"\n",
    "prompt_for_roleplay = \"Please act as a pirate and play a roleplay game with me.\"\n",
    "\n",
    "# function to clear the coversation\n",
    "def reset() -> List:\n",
    "    return interact_roleplay([], prompt_for_roleplay)\n",
    "\n",
    "# function to call the model to generate\n",
    "def interact_roleplay(chatbot: List[Tuple[str, str]], user_input: str, temp=1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * Arguments\n",
    "\n",
    "      - user_input: the user input of each round of conversation\n",
    "\n",
    "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
    "              The higher the temperature is, the more creative response you will get.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        messages = []\n",
    "        for input_text, response_text in chatbot:\n",
    "            messages.append({'role': 'user', 'parts': [input_text]})\n",
    "            messages.append({'role': 'model', 'parts': [response_text]})\n",
    "\n",
    "        messages.append({'role': 'user', 'parts': [user_input]})\n",
    "\n",
    "        response = model.generate_content(\n",
    "          messages,\n",
    "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "          safety_settings=[\n",
    "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        chatbot.append((user_input, response.text))\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
    "    return chatbot\n",
    "\n",
    "def export_roleplay(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
    "    '''\n",
    "    * Arguments\n",
    "\n",
    "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
    "\n",
    "      - description: the description of this task\n",
    "\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"description\": description}\n",
    "    with open(\"part2.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "first_dialogue = interact_roleplay([], prompt_for_roleplay)\n",
    "\n",
    "# This part constructs the Gradio UI interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(f\"# Part2: Role Play\\nThe chatbot wants to play a role game with you, try interacting with it!!\")\n",
    "    chatbot = gr.Chatbot(value = first_dialogue)\n",
    "    description_textbox = gr.Textbox(label=f\"The character the bot is playing\", interactive = False, value=f\"{character_for_chatbot}\")\n",
    "    input_textbox = gr.Textbox(label=\"Input\", value = \"\")\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
    "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"Send\")\n",
    "        reset_button = gr.Button(value=\"Reset\")\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
    "        export_button = gr.Button(value=\"Export\")\n",
    "    sent_button.click(interact_roleplay, inputs=[chatbot, input_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_roleplay, inputs=[chatbot, description_textbox])\n",
    "\n",
    "\n",
    "demo.launch(debug = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customized Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Program Files\\Python\\Python311\\Lib\\site-packages\\gradio\\components\\chatbot.py:273: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The first is for you to tell the user that the chatbot can perform certain task\n",
    "# The second one is the prompt that make the chatbot able to do certain task\n",
    "chatbot_task = \"Antonym bot\"\n",
    "prompt_for_task = \"Give me the antonym of the following words.\"\n",
    "\n",
    "# function to clear the conversation\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# function to call the model to generate\n",
    "def interact_customize(chatbot: List[Tuple[str, str]], prompt: str ,user_input: str, temp = 1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * Arguments\n",
    "\n",
    "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
    "\n",
    "      - prompt: the prompt for your desginated task\n",
    "\n",
    "      - user_input: the user input of each round of conversation\n",
    "\n",
    "      - temp: the temperature parameter of this model. Temperature is used to control the output of the chatbot.\n",
    "              The higher the temperature is, the more creative response you will get.\n",
    "\n",
    "    '''\n",
    "    try:\n",
    "        messages = []\n",
    "\n",
    "        for input_text, response_text in chatbot:\n",
    "            messages.append({'role': 'user', 'parts': [input_text]})\n",
    "            messages.append({'role': 'model', 'parts': [response_text]})\n",
    "\n",
    "        messages.append({'role': 'user', 'parts': [prompt+ \"\\n\" + user_input]})\n",
    "\n",
    "        response = model.generate_content(\n",
    "          messages,\n",
    "          generation_config=genai.types.GenerationConfig(temperature=temp),\n",
    "          safety_settings=[\n",
    "          {\"category\": \"HARM_CATEGORY_HARASSMENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_HATE_SPEECH\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\"threshold\": \"BLOCK_NONE\",},\n",
    "          ]\n",
    "        )\n",
    "\n",
    "        chatbot.append((user_input, response.text))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        chatbot.append((user_input, f\"Sorry, an error occurred: {e}\"))\n",
    "    return chatbot\n",
    "\n",
    "def export_customized(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
    "    '''\n",
    "    * Arguments\n",
    "\n",
    "      - chatbot: the model itself, the conversation is stored in list of tuples\n",
    "\n",
    "      - description: the description of this task\n",
    "\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"description\": description}\n",
    "    with open(\"part3.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "# this part is to construct the Gradio UI interface\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Part3: Customized task\\nThe chatbot is able to perform a certain task. Try to interact with it!!\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    desc_textbox = gr.Textbox(label=\"Description of the task\", value=chatbot_task, interactive=False)\n",
    "    prompt_textbox = gr.Textbox(label=\"Prompt\", value=prompt_for_task, visible=False)\n",
    "    input_textbox = gr.Textbox(label=\"Input\")\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Temperature\\n Temperature is used to control the output of the chatbot. The higher the temperature is, the more creative response you will get.\")\n",
    "        temperature_slider = gr.Slider(0.0, 1.0, 0.7, step = 0.1, label=\"Temperature\")\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"Send\")\n",
    "        reset_button = gr.Button(value=\"Reset\")\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"#  Save your Result.\\n After you get a satisfied result. Click the export button to recode it.\")\n",
    "        export_button = gr.Button(value=\"Export\")\n",
    "    sent_button.click(interact_customize, inputs=[chatbot, prompt_textbox, input_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_customized, inputs=[chatbot, desc_textbox])\n",
    "\n",
    "demo.launch(debug = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
