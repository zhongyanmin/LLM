{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFOUfh2k1jFN"
      },
      "source": [
        "# Understand what Generative AI is thinking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ElcWXfA8o3n"
      },
      "source": [
        "## Machine Translation Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e8MpYJ9LgBy"
      },
      "outputs": [],
      "source": [
        "import inseq\n",
        "\n",
        "# List of attribution methods to be used\n",
        "attribution_methods = ['saliency', 'attention']\n",
        "\n",
        "for method in attribution_methods:\n",
        "    print(f\"======= Attribution Method: {method} =======\")\n",
        "    # Load the Chinese-to-English translation model and set up the attribution method\n",
        "    model = inseq.load_model(\"Helsinki-NLP/opus-mt-zh-en\", method)\n",
        "\n",
        "    # Apply attribution to the input text using the specified method\n",
        "    attribution_result = model.attribute(\n",
        "        input_texts=\"我喜歡機器學習和人工智慧。\",\n",
        "        step_scores=[\"probability\"],\n",
        "    )\n",
        "\n",
        "    # Remove '▁' from the tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "    for attr in attribution_result.sequence_attributions:\n",
        "        for item in attr.source:\n",
        "            item.token = item.token.replace('▁', '')\n",
        "        for item in attr.target:\n",
        "            item.token = item.token.replace('▁', '')\n",
        "\n",
        "    # Display the attribution results\n",
        "    attribution_result.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lgZR0CJ-7xs"
      },
      "source": [
        "## Sentence Completion Task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJ650ekw5jo-"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\"gpt2-xl\", load_in_8bit=True, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Nfr55IvSCuw"
      },
      "outputs": [],
      "source": [
        "for method in attribution_methods:\n",
        "    # Load the model with the specified attribution method\n",
        "    inseq_model = inseq.load_model(model, method)\n",
        "\n",
        "    # Apply attribution to the input text using the specified method\n",
        "    attribution_result = inseq_model.attribute(\n",
        "        input_texts=\"The first president of America is\",\n",
        "        step_scores=[\"probability\"],\n",
        "    )\n",
        "\n",
        "    # Remove 'Ġ' from GPT2's BPE tokenizer in the prefix to avoid confusion (You can ignore this part of code)\n",
        "    for attr in attribution_result.sequence_attributions:\n",
        "        for item in attr.source:\n",
        "            item.token = item.token.replace('Ġ', '')\n",
        "        for item in attr.target:\n",
        "            item.token = item.token.replace('Ġ', '')\n",
        "\n",
        "    # Display the attribution results\n",
        "    attribution_result.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
